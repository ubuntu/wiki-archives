{|
| '''Warning'''
* This is a '''readonly''' and '''text-based''' archive of a deprecated wiki.
* '''Images''' and '''attachments''' have been removed to conserve space.
* '''Links''' may not work and there may be formatting issues.
* A '''compressed''' version with images and the original syntax is in the repo '''Releases'''.
|}

__TOC__

''The following is a suggestion for improving software speech synthesis for Dapper. It was written by LukeYelavich (and posted here by HenrikOmma).''

At the moment, speech synthesis can be used in Linux, but not without
considerable time for setup, and configuration, particularly software
synthesis. Hardware speech synthesizers can be used, but all supported
synthesizers cannot be used with all screen reader applications. Linux
can be installed using speech synthesis, but only with hardware, which
limits the number of people who can install Linux independently.

Independant installation of Linux would be greatly improved, if software
speech synthesis with a screen reader were available at install time.
With Ubuntu Express, this won't be so difficult, however we do need to
be able to have the language, country, and keyboard selections spoken,
which requires more work.

There are also one or two hardware speech synthesizers that require
proprietary firmware to be loaded in order to be used. This is possible
to do in Linux, but there is no user friendly way to do so. We should
provide a mechanism to install and set up the firmware, to allow people
to use the speech synthesizer.

Added to that, if the user uses a screen reader with speech during the
installation, it should be configured and ready to use from the first
boot of the newly installed system.

Finally, there are also a few software speech synthesizers that are
commercially available. We should provide an easy way for users to get
them installed, and configured to work with as many applications as
possible. If the user has more than one sound card installed, they
should be able to set which sound card gets used for speech output.

== Discussion ==

I see several separate topics here. I think it would be good if we could break this topic down into parts as much as possible to make it easier to track our progress.

* Free speech synthesizers:
** Options for GUI: Festival, Flite, FeeTTS (Java), others? -- Are there significant advantages of one over another? Which one represents the 'future'.
*** Festival is probably the future, due to the modular design it has, but more languages need to be developed, or alternative synths for other languages need to be looked into.
* Speakup -- Can provide speech at the command line (and during installation?)
** Needs a kernel patch -- can we provide pre-compiled kernels in Universe?
*** Yes speakup can provide screen reading on the console, and during installation. However, spoken installation is only possible with hardware at the moment. It would be nice for Ubuntu to be the first distro to offer software speech at install time. As to providing alternate kernels in universe, yes we could do that, but if we want to ship an accessible kernel/install on the main CD, we will have to get speakup into main somehow.

* Once we pick one, what is required to make it 'just work'?
** Does it play nicely with the sound daemons, with known sound cards?
** Ease of installation: Can we make useful meta-packages or install scripts
*** Particularly for proprietary speech synthesizers, metapackages for easier installation and configuration will be required to get them set up. For example, a couple of proprietary synths require you to enter a serial code in order to install them. I have worked out ways of wrapping these prompts in a script, so we could easily offer a debconf prompt to ask for the serial code, and where the tarball of the synth is currently stored. As for sound daemons, hopefully this will be dropped for dapper if I read the sound specs correctly, so it won't be so much of a problem. Most of the synths still use OSS, particularly the proprietary ones. It is possible to use an OSS app with alsa and dmix, but it is not trivial, and the resulting sound quality and performance may be a problem.

* Independent installation without special hardware
** Does this basically require the first-boot kernel to have the Speakup patch? -- Can we make an alternative kernel to be selected at the CD boot prompt? (by F-key)
*** Yes that could be done, but the user needs to know that they need to do that before booting the CD.
** Can recorded sound files be used?
*** Recorded sounds would be practically impossible, considering the number of languages we have to support, and even if the files were at their lowest quality possible with compression, a lot of CD space would be needed, as they certainly would not fit into the installer root image.

* Hardware speech synthesizer firmware
** I assume the advantage of these units is that they provide better speech and/or use less computing resources. Do we need to provide for this at install time or would it be sufficient to allow users to upgrade from software to hardware speech on a running system?
*** I feel that hardware speech support should be available from the earliest point possible. Detecting and configuring the sound card, as well as software speech at the start of the installer is a non-trivial task. There is the chance that the user's soundcard may not be detected properly or doesn't work well in such a stripped environment as the installer, so if the user has hardware, they should be allowed to use it.

* Proprietary software speech synthesizers -- volunteers could package these for multiverse, but it probably cannot represent our front-line effort.
** There are some festival voices that are not free which I think are already in multiverse, but the speech synthesizers I am referring to are those that the user has to buy from a company, and install. It would be nice to offer the user an easy way of installing these synthesizers, so they can be configured properly to work with Ubuntu without too much work for the user.
----
CategoryAccessibility
