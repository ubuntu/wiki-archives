{|
| '''Warning'''
* This is a '''readonly''' and '''text-based''' archive of a deprecated wiki.
* '''Images''' and '''attachments''' have been removed to conserve space.
* '''Links''' may not work.
* A '''full compressed version''' of the wiki is available on archive.org
|}

__TOC__

=== Getting A Grip on Your Apps: Multitouch on GTK apps using Libgrip - Instructors: Jussi Pakkanen ===

{{{#!irc
[15:59] <dpm> Everyone ready for the last day or UADW?
=== ChanServ changed the topic of #ubuntu-classroom to: Welcome to the Ubuntu Classroom - https://wiki.ubuntu.com/Classroom || Support in #ubuntu || Upcoming Schedule: http://is.gd/8rtIi || Questions in #ubuntu-classroom-chat || Event: App Developer Week - Current Session: Getting A Grip on Your Apps: Multitouch on GTK apps using Libgrip - Instructors: Satoris
[16:00] <dpm> the people on #ubuntu-classroom-chat say yes! :)
[16:01] <ClassBot> Logs for this session will be available at http://irclogs.ubuntu.com/2011/09/09/%23ubuntu-classroom.html following the conclusion of the session.
[16:01] <dpm> Hello everyone and welcome to this last edition of the Ubuntu App Developer Week
[16:01] <dpm> lots of sessions with great speakers today,
[16:02] <dpm> speaking of which, let's give a warm welcome to Satoris, who'll be talking about adding multitouch support to your GTK+ apps with libgrip!
[16:03] <Satoris> Hi all. My name is Jussi Pakkanen, and I am a member of the uTouch team at Canonical.
[16:03] <Satoris> Today I'll be talking about adding gesture support for existing apps using libgrip.
[16:04] <Satoris> Libgrip is a simple, "GTK-flavored" library for gestures.
[16:04] <Satoris> The uTouch stack has lots of other parts as well, but I won't talk about them. If there is demand and time at the end, I can give an overview.
[16:05] <Satoris> The first thing you might want to do is to open the libgrip tutorial page, which is here: https://wiki.ubuntu.com/Multitouch/GripTutorial
[16:06] <Satoris> I'm going to go through it so it pays to have it open. Get the code as well, it is attatched to the page.
[16:06] <Satoris> A word of warning, I'm going to describe libgrip 0.3.1 and newer.
[16:07] <Satoris> This is not available in Natty, and won't be. So if you are using Natty, you need to compile libgrip from source.
[16:07] <Satoris> There is also a known bug in Oneiric's libgrip. We pushed a fix to that some 20 minutes ago.
[16:08] <Satoris> So it should be available soon.
[16:09] <Satoris> The main things to know about libgrip are device types and subscriptions.
[16:09] <Satoris> There are three different kinds of devices: touchscreens, touchpads and independent devices (Apple Magic Mice).
[16:10] <Satoris> Whenever you say you want certain types of gestures, you create a subscription.
[16:11] <Satoris> So the basic structure of a libgrip application is to subscribe to gestures, such as "one finger drags on touchscreens" or "two finger rotates on any device".
[16:11] <Satoris> When these gestures are performed, libgrip calls your callback functions.
[16:11] <Satoris> It is very similar to how GTK sends "redraw" or "mouse motion" events.
[16:12] <Satoris> I forgot to mention that libgrip 0.3 requires GTK 3.0. You can't use it on GTK+ 2 apps.
[16:12] <Satoris> But who has those anymore. :)
[16:13] <Satoris> The subscription is describe on the tutorial page under "subscription".
[16:14] <Satoris> It is very straightforward.
[16:14] <Satoris> In the tutorial all subscriptions have the same callback function.
[16:15] <Satoris> You can have different ones, it does not really matter.
[16:15] <Satoris> People seem to prefer having one and then demultiplexing stuff by themselves.
[16:16] <Satoris> In the test app we have a viewport and we want to be able to move it around with finger drags.
[16:17] <Satoris> So we subscribe two finger drags for all devices and also one finger drags for touchscreens.
[16:18] <Satoris> Very simple.
[16:18] <Satoris> The gesture callback function is also quite straightforward.
[16:19] <Satoris> We check how much the user has dragged and update the viewport correspondingly.
[16:19] <Satoris> However there is one thing to note.
[16:20] <Satoris> When dragging on a touchpad, the scroll directions need to be changed.
[16:20] <Satoris> This is because historically dragging down on a touchpad moves the "document" up.
[16:21] <Satoris> This is something that may change in the future, newest OSX has the option to make drags on touchpad the same as on touchscreens.
[16:22] <Satoris> Libgrip does not invert the axes for you, because it can't know whether you are dragging an object or scrolling a view.
[16:23] <Satoris> This is the app developer's responsibility.
[16:24] <Satoris> The rest of the code is pretty standard GTK.
[16:24] <Satoris> So in this case adding gestures took a couple of dozen of lines of code.
[16:25] <Satoris> For a more complicated example, I recommend you to look at the gesture patches for Evince and EOG.
[16:25] <Satoris> They can be found in the respective oneiric source packages.
[16:26] <Satoris> This means that the oneiric's EOG and Evince will be gesture enabled out of the box.
[16:28] <Satoris> Those patches have drags, document rotations and pinch to zoom.
[16:29] <Satoris> Subscribing to gestures is quite simple, but there are certain things that will most likely surprise you.
[16:29] <Satoris> The main thing being that gestures that human beings make are rarely pure.
[16:30] <Satoris> Simply dragging two fingers along most likely triggers pinches or rotations as well.
[16:30] <Satoris> That is because the human beings are not robots, at least not yet.
[16:31] <Satoris> Their fingers move involuntarily, even if they try to keep them steady.
[16:32] <Satoris> Unfortunately it is impossible to differentiate between "drag only, but fingers get slightly rotated accidentally" and "drag with a touch of rotation" in the general case.
[16:33] <Satoris> So again, the app developer has to do work here.
[16:34] <Satoris> Usually it is best to design the UI so that spurious events do not matter.
[16:35] <Satoris> The basic guideline is that the gesture recognition stack can not read the user's mind. That is the job of an app developer.
[16:36] <Satoris> Another thing to note is that trackpads especially have very different sizes.
[16:37] <Satoris> A basic mini-laptop's touchpad is only about one quarter (or less) of a MacBook Pro's touch pad.
[16:38] <Satoris> So you really have to consider these things when dealing with, e.g. pinch sensitivity.
[16:38] <Satoris> And on the other hand if you want your app to be used on a touch screen, those are even bigger.
[16:40] <Satoris> And the last thing: you should probably never subscribe to single finger drags on touchpads.
[16:40] <Satoris> That grabs the mouse pointer, because one finger drags are mapped to mouse motion.
[16:42] <Satoris> That's roughly what I had prepared. I'm open for questions.
[16:44] <ClassBot> tomalan asked: The MacBook Pro touchpad can distinguish between "tap" and "click". Is libgrip also capable of this?
[16:45] <Satoris> If by "click" you mean pushing the pad so that it produces a mouse click, then yes.
[16:45] <Satoris> Pushing it so hard that it produces the clicking sound, that is.
[16:46] <Satoris> I use a Macbook for development (and am using it at this very moment) and have set it up so that taps do not produce mouse clicks and you use two fingers for scrolling.
[16:47] <Satoris> Rather than using the edge for scrolling.
[16:48] <Satoris> You can get the taps by subscribing to the GRIP_GESTURE_TAP event.
[16:49] <Satoris> I'm not sure what happens if you have set it up so that tapping the pad lightly causes a mouse click.
[16:50] <Satoris> I find that behaviour hugely irritating and always disable it as the first thing I do.
[16:50] <ClassBot> tomalan asked: In OSX i also like the feature that i open the context menu by "clicking" with two fingers and if I keep clicked and move to the menu entry and then release the selected menu entry gets activated. Do you know if it's possible to configure Ubuntu to behave the same?
[16:50] <ClassBot> There are 10 minutes remaining in the current session.
[16:51] <Satoris> You can set up Ubuntu so that clicking with two fingers creates a right-click. That brings up a context menu most of the time.
[16:51] <Satoris> This behaviour might even be the default. Not sure though.
[16:53] <Satoris> You have to release one finger to be able to select stuff on the menu.
[16:53] <ClassBot> tomalan asked: I meant that i keep the pad pressed with one finger, navigate to my target with the other one and the release the second finger to activate the entry, so i don't have to click twice
[16:54] <Satoris> This needs some plumbing and code changes that are not present currently AFAIK. But we will work on these issues in the next cycle.
[16:55] <ClassBot> There are 5 minutes remaining in the current session.
[16:58] <Satoris> Last chance for questions.}}}
