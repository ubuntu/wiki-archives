{|
| '''Warning'''
* This is a '''readonly''' and '''text-based''' archive of a deprecated wiki.
* '''Images''' and '''attachments''' have been removed to conserve space.
* '''Links''' may not work and there may be formatting issues.
* A '''compressed''' version with images and the original syntax is in the repo '''Releases'''.
|}

__TOC__


== Creating virtual machines ==

Now that KVM is installed, let's see how we create our first VM. This can be done using:
* <nowiki>[[http://virt-manager.et.redhat.com|virt-manager]]</nowiki>: a GUI tool
* <nowiki>[[http://www.howtoforge.com/installing-kvm-guests-with-virt-install-on-ubuntu-8.10-server|virt-install]]</nowiki>, a python script developed by Red Hat
* <nowiki>[[https://help.ubuntu.com/8.04/serverguide/C/ubuntu-vm-builder.html|ubuntu-vm-builder]]</nowiki>, developed by Canonical.

=== Ubuntu-vm-builder: the fast & powerful way to create Ubuntu JEOS VMs ===

<nowiki>[[http://doc.ubuntu.com/ubuntu/serverguide/C/ubuntu-vm-builder.html|Ubuntu-vm-builder]]</nowiki> is probably the best tool to use if you want to create VMs running <nowiki>[[JeOS|Ubuntu JEOS 8.04]]</nowiki>, as the install is entirely scripted (very fast).

This tool is packaged, and in universe:

<pre>
sudo apt-get install ubuntu-vm-builder
</pre>
'''Note''': you will need to have grub installed for vmbuilder to work. If you're using lilo to boot the host you will have to install the grub package. You can still use lilo to boot the host OS, but the guests will boot with grub. The grub command needs to be install on the host for the guest image to build.

'''Note for 8.10 (intrepid)''': the package is now named '''python-vm-builder''', the command is now named '''vmbuilder''' and you can find a <nowiki>[[https://help.ubuntu.com/community/JeOSVMBuilder|detailed tutorial on the wiki]]</nowiki>.

'''Note''': make sure you have big enough /tmp (1GB or more). Also, some locales will crash ubuntu-vm-builder; en_US is safe.

==== Basic use ====

Here is a very basic example of how to use it:

<pre>
sudo ubuntu-vm-builder kvm hardy
</pre>

This will create an Ubuntu Hardy, with all options set to default.
Note: if you want to use Virsh to manage your virtual machines as detailed below, you must add this parameter:

<pre>
--libvirt qemu:///system
</pre>

The javascript does not have an option for this itself, unfortunately.

'''Note''': when using --libvirt, the xml file is injected into libvirt and not stored locally. Use <code>virsh -c qemu:///system</code> or <code>virt-manager -c qemu:///system</code> to start your machine or modify its configuration.

==== More complex example ====

Now here is a somewhat more complex example:

<pre>
ubuntu-vm-builder kvm hardy \
                  --domain newvm \
                  --dest newvm \
                  --arch i386 \
                  --hostname hostnameformyvm \
                  --mem 256 \
                  --user john \
                  --pass doe \
                  --ip 192.168.0.12 \
                  --mask 255.255.255.0 \
                  --net 192.168.0.0 \
                  --bcast 192.168.0.255 \
                  --gw 192.168.0.1 \
                  --dns 192.168.0.1 \
                  --mirror http://archive.localubuntumirror.net/ubuntu \
                  --components main,universe \
                  --addpkg acpid \ 
                  --addpkg vim \
                  --addpkg openssh-server \
                  --addpkg avahi-daemon \
                  --libvirt qemu:///system ;
</pre>

This will create a new Ubuntu Hardy VM called "newvm", the hostname will be set to "hostnameformyvm", the network will be configured with a static IP address and a gateway at address 192.168.0.1. The --mirror will tell the script to download the packages from a local Ubuntu mirror instead of the default server (this may speed up by a lot the time necessary to create the VM). The components argument will enable main and universe by default on the VM, --addpkg vim will install vim, and finally the last argument will automatically add the newly created VM to KVM.

By adding 'openssh-server' with --addpkg, we will be able to ssh into our new machine once its started (provided the networking works correctly).

By adding 'avahi-daemon' the VM will register an MDNS record ('ubuntu.local' in this case), so you can ssh right in without bothering with DHCP assigned IP addresses.

Note: The manual isn't specific about the --exec option, used to execute a script file during the vm build process. If you specify the --exec option then you must provide the full path to the script you are executing. Not doing so will cause the installer to tell you that it can't find the script file.

'''Bug notice: ''' it seems that the package 'linux-package' is not found during the machine building process unless 'restricted' is also specified as a component option to ubuntu-vm-builder. If not specified, you'll get a non-functioning system that boots into grub only. This line makes it work for me:

<pre>
--components 'main,universe,restricted'
</pre>

I'm assuming this is a bug in ubuntu-vm-builder.

'''Package requirement notice: ''' When managing your guests, the shutdown/reboot commands send by virsh are ACPI events. So in order for your machine to shutdown/reboot, you must have ACPI support. If the guest O/S is Ubuntu run "sudo apt-get install acpid".

==== Starting Guest created in "complex example" ====
Once your Guest is created, you can see it by typing the following :
<pre>
virsh 'list --all'
</pre>
You'll see :
<pre>
 Id Name                 State
----------------------------------
 - YourGuestName         shut off
</pre>

To start your virtual server, you can type :
<pre>
virsh start YourGuestName
</pre>

==== Accessing the new server remotely with SSH tunnel / VNC ====

If your server is remote, you can use the two following commands from your local machine {

The first guest is accessible, by default, on vnc:127.0.0.1:5900. If you are remotely accessing the server, you can setup an ssh tunnel and vnc onto the virtual server.

From terminal on your local machine :
<pre>
ssh YOURUSER@YOURSERVER -L5900:127.0.0.1:5900
</pre>

Now go into Applications -> Internet -> Remote Desktop Viewer.
Protocol : VNC
Host : 127.0.0.1
Everything else is by default.

This will connect you to the first guest.

==== Install on a raw block device ====

Ubuntu-vm-builder doesn't allow you to create the VM on a raw block device yet (like a standalone partition, or a iSCSI share). You can use ubuntu-vm-builder to create the qcow2 image and then move the VM to the block device with qemu-img though; if /dev/sdb is the disk device on which you want to move the virtual machine:

<pre>
sudo qemu-img convert root.qcow2 -O raw /dev/sdb
</pre>

Edit the XML definition file for the VM in /etc/libvirt/qemu/, and set the source file to be:
<pre>
<source file='/dev/sdb'/>
</pre>

Redefine the VM and start it; it is now running from /dev/sdb.

Ubuntu-vm-builder is a very powerful tool - to get a more detailed list of its capabilities, use ubuntu-vm-builder --help.

=== Create VMs running other operating systems: virt-install ===

Virt-install is radically different in the way it works. Instead of creating automagically a new VM, it will allow you to boot on an iso, and therefore to install almost any operating system.  For a list of supported operating system, consult <nowiki>[[http://www.linux-kvm.org/page/Guest_Support_Status|kvm's official webpage]]</nowiki>.

As you need virt-install to setup Windows guests, we will here describe how to install windows XP. There are a couple of small issues during the install, so I will also describe the workarounds.

==== Example Windows install ====
{{http://waste.mandragor.org/windows-kvm.png}}

NB: The following install is for Windows XP under KVM-62 (default in Hardy as time of writing). I have been unable to run windows 2000 server in accelerated mode on it. To run windows 2000 server, I use the KVM-72 backport for Hardy provided by Soren in his PPA: https://launchpad.net/~soren/+archive.

Copy the ISO of the system you want to install to your working directory:
<pre>
yhamon@paris:~$ ls *.iso
ubuntu-8.04-server-i386.iso  windowsxpsp2.iso
</pre>
or create an ISO from a cd/dvd:
<pre>
dd if=/dev/dvd of=dvd.iso
</pre>

Install virt-install:
<pre>
sudo apt-get install python-virtinst
</pre>

Then, you need to run virt-install. On Ubuntu Hardy, with KVM-62, the install of windows XP doesn't work when accelerated (ie, using --accelerate), so run the install without that argument, and replace qemu by kvm in the XML defintiion file (in /etc/libvirt/qemu) after the first reboot.

<pre>
sudo virt-install --connect qemu:///system -n xpsp2 -r 512 -f windows.qcow2 -s 12 -c windowsxpsp2.iso --vnc --noautoconsole --os-type windows --os-variant winxp
</pre>

'''Note for 8.10 (intrepid)''': to make above command work add --hvm option to enable fully virtualized guest.

'''Note for 9.10 (karmic)''': if virtual machine just freezes after 1 - 2 minutes after beginning of windows xp installation just use --accelerate option instead of --hvm

This will boot a new VM from the ISO. Connect to the new VM using virt-viewer:

<pre>
virt-viewer -c qemu:///system xpsp2
</pre>

Or if KVM is running on a different server:

<pre>
virt-viewer -c qemu+ssh://ip/system xpsp2
</pre>

You can now start the install. Another problem is that after the first reboot, in the process of the installation, the windows installer will complain that it can not see the disk anymore. In the XML definition of the VM again, add this to the list of devices:

<pre>
<domain type='kvm'>
  [...]
  <devices>
    [...]
    <disk type='file' device='cdrom'>
      <source file='//home/yhamon/windowsxpsp2.iso'/>
      <target dev='hdc' bus='ide'/>
      <readonly/>
    </disk>
  </devices>
</domain>
</pre>

Redefine the VM in virsh (sudo virsh define /etc/libvirt/qemu/xpsp2.xml) and restart the VM - it should work fine.

Another problem with virt-install in combination with Windows is that the created disk image is corrupted. At first the installation seems to work, but then after a reboot it stops with the message 'A read error occured'. This can be easily fixed by creating a new disk image (prior to installation):
<pre>
qemu-img create -f qcow2 disk0.qcow2 12G
</pre>
Overwrite the qcow2 file created by virt-install by this new file, reboot your VM and you are ready to go.

==== Example Ubuntu install ====
You can perform the following to install Ubuntu Hardy:<pre>
sudo virt-install --connect qemu:///system -n hardy -r 512 -f hardy.qcow2 -s 12 -c hardy-server-amd64.iso --vnc --noautoconsole --os-type linux --os-variant ubuntuHardy --accelerate --network=network:default
</pre>

The '--network' option sets up the machine to use the default libvirt network. You can see available libvirt networks with:<pre>
virsh net-list --all
</pre>

==== Other Operating Systems ====
Other Operating Systems can be installed using the same method as above. See 'man virt-install' for more information on different options for your virtual machine and supported OS types and OS variants.

'''Warning:''' this method fails with Fedora LiveCD installations and possibly others; see the bug here: https://bugs.launchpad.net/ubuntu/+source/kvm/+bug/220463

=== Cloning a virtual machine ===
You can clone an existing virtual machine using the virt-clone tool.  This duplicates the disk image and sets up the virtual machine domain configuration.

If you wish to clone a virtual machine named ''srchost'' to a new machine ''newhost'', ensure that the virtual machine ''srchost'' is not running and execute the following command.
<pre>
$ virt-clone --connect=qemu:///system -o srchost -n newhost -f /path/to/newhost.qcow2
</pre>

=== Create a virtual machine from pre-existing image ===
Assuming:

* Virt-manager is being used to manage virtual machines.
* You wish to add a pre-existing image to virt-manager.

Use case:

Using qcow2 with overlays, you can experiment heavily with your virtual machines without having to perform complete reinstalls if you manage to corrupt them.  A side effect of this method in comparison to cloning, is that less disk space is used.

Procedure:

1. Create the hard drive image with qcow2 format:
<pre>
$ qemu-img create -f qcow2 <image name>.qcow2
</pre>
2. Install the virtual machine using virt-manager:

Instead of allowing virt-manager to create a new drive image, simply
direct it to use the image you created in the previous step.

3. Create the overlay:
<pre>
$ qemu-img create -f qcow2 -b <image name>.qcow2 <image name>.ovl
</pre>
4. Create virtual image XML descriptor.

Read first:
<pre>
$ man virt-image
$ man 5 virt-image
</pre>
Copy the XML file created in step 2 above:
<pre>
$ cp ~/.libvirt/qemu/<vm name>.xml overlay.xml
</pre>
Then using your favorite editor, open and edit the copied XML file:
<pre>
$ <editor> overlay.xml
</pre>
Create the virtual image XML descriptor based on the virt-image(5)
manpage.  I simply commented out the original text, and used it as
a guide when creating the new descriptor.

5. Create the new virtual machine from the image descriptor:
<pre>
$ virt-image --vnc overlay.xml
</pre>
6. Run and test the new virtual machine based on the overlay.

Open the new virtual machine in virt-manager and test to your hearts
content.  If you 'break' the virtual machine, simply destroy and
delete it.  Then recreate the overlay image and recreate the overlay
virtual machine as described above.  You can commit the overlay changes
to the base image if desired, see the qemu-img manpage for details.

=== See also ===

The <nowiki>[[..-FAQ#systemadjustments|system specific adjustment recommended in the FAQ]]</nowiki>.

<nowiki>[[http://packages.ubuntu.com/search?keywords=apt-cacher-ng|apt-cacher-ng]]</nowiki> for mirroring.  You can reduce setup time to 3-4 minutes using ubuntu-vm-builder on a reasonable machine.

----
CategoryVirtualization
